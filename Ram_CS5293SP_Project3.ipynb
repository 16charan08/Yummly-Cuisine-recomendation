{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ram_CS5293SP_Project3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "axjwjd6sYcH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4ede7549-644f-43a8-c339-88b48c94e178"
      },
      "source": [
        "import gensim as gensim\n",
        "import networkx\n",
        "import numpy as np  \n",
        "import os\n",
        "import pandas as pd  \n",
        "import glob\n",
        "import json\n",
        "import gc\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk import flatten\n",
        "from pickle import load\n",
        "from pickle import dump"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-usLfLJxZFeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Document normalize function\n",
        "def normalize_document(txt):\n",
        "    txt = txt.lower()\n",
        "    txt = txt.strip()\n",
        "    tokens = nltk.word_tokenize(txt)\n",
        "    clean_tokens = [t for t in tokens if t not in stop_words]\n",
        "    wordnet_lem = [WordNetLemmatizer().lemmatize(w) for w in clean_tokens]\n",
        "    stems = [nltk.stem.SnowballStemmer('english').stem(w) for w in wordnet_lem]\n",
        "    return ' '.join(stems)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD5DKaB-gCJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returning dataframe with normalized data\n",
        "def normalizedf(df_ini):\n",
        "  df_ini = df_ini\n",
        "  x = []\n",
        "  for i in df_ini['ingredients']:\n",
        "      i = ' '.join(i)\n",
        "      #print(i)\n",
        "      x.append(normalize_document(i))\n",
        "  df = df_ini\n",
        "  df[\"normalized_ing\"] = x\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xKaFKNVgX7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting into vector form\n",
        "def tfidfvecinput(input,df):\n",
        "  input = input\n",
        "  joined_input = []\n",
        "  input = ','.join(input)\n",
        "  joined_input.append(input)\n",
        "  input_normalized = []\n",
        "  input_normalized.append(normalize_document(joined_input[0]))\n",
        "  y = []\n",
        "  for every in df[\"normalized_ing\"]:\n",
        "      y.append(every)\n",
        "  y.insert(0,input_normalized[0])\n",
        "  vectorizer = TfidfVectorizer(stop_words='english')\n",
        "  tfidf_matrix_train = vectorizer.fit_transform(y).todense()\n",
        "  return tfidf_matrix_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0TCE1MVifdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding cosine similarity score with respect to input\n",
        "# Reference :- http://carrefax.com/new-blog/2017/7/4/cosine-similarity\n",
        "def cosinesim(mat,df):\n",
        "  simi = cosine_similarity(mat[0:1], mat).flatten()\n",
        "  #print(len(simi[1:]))\n",
        "  #print(len(df))\n",
        "  df[\"score\"] = simi[1:]\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uIO6CIplz4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting Top N ID's that are related to our input\n",
        "def getcloseid(df,N):\n",
        "  final_df = df.sort_values(by=[\"score\"],ascending=False)\n",
        "  result = final_df[[\"id\",\"score\"]].head(N)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frkJ_JlM2RBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving model\n",
        "def savemodel(df):\n",
        "  vectorizer = TfidfVectorizer(stop_words='english')\n",
        "  tfidf_matrix = vectorizer.fit_transform(df[\"normalized_ing\"]).todense()\n",
        "  cuisins = df[\"cuisine\"]\n",
        "  lb = LabelEncoder()\n",
        "  Y = lb.fit_transform(df[\"cuisine\"])\n",
        "  X = tfidf_matrix\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
        "  clf = RandomForestClassifier()\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test,y_pred)*100  \n",
        "  dump(clf, open('Rfcmodel.pkl', 'wb'))\n",
        "  print(accuracy)\n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDu4FQs9EKzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting cuisine based upon the input ingredients\n",
        "def predictcuisine(input,model,df):\n",
        "  joined_input = []\n",
        "  input = ','.join(input)\n",
        "  joined_input.append(input)\n",
        "  joi = []\n",
        "  joi.append(normalize_document(joined_input[0]))\n",
        "  vectorizer = TfidfVectorizer(stop_words='english')\n",
        "  tfidf_matrix = vectorizer.fit_transform(df[\"normalized_ing\"]).todense()\n",
        "  ini = vectorizer.transform([joi[0]]).todense()\n",
        "  y_predin = model.predict(ini)\n",
        "  lb = LabelEncoder()\n",
        "  Y = lb.fit_transform(df[\"cuisine\"])\n",
        "  return lb.inverse_transform(y_predin)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1yq8Bb-Mqrn",
        "colab_type": "text"
      },
      "source": [
        "## ***Execution*** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwhs32t5hYB9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f30cf434-594c-4e26-aa54-0585109d86b9"
      },
      "source": [
        "\n",
        "input= [\"coriander powder\",\"ground turmeric\",\"red pepper flakes\",\"japanese eggplants\",\"plums\",\"grated parmesan cheese\",\"fresh parsley\",\"tomatoes with juice\"]\n",
        "df_ini = pd.read_json('yummly.json')\n",
        "norm_df = normalizedf(df_ini)\n",
        "mat = tfidfvecinput(input,norm_df)\n",
        "updated_df = cosinesim(mat,norm_df)\n",
        "N = 10\n",
        "if not os.path.exists('Rfcmodel.pkl'):\n",
        "  accu = savemodel(updated_df)\n",
        "else:\n",
        "  print(\"model is already executed with\",accu)\n",
        "model = load(open('Rfcmodel.pkl', 'rb'))\n",
        "print(\"Top10 ID's for given input\")\n",
        "print(getcloseid(updated_df,N))\n",
        "print(\"Cuisine for given input\",predictcuisine(input,model,df_ini))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model is already executed with 75.14770584538026\n",
            "Top10 ID's for given input\n",
            "          id     score\n",
            "26586  39414  0.527524\n",
            "25495  15840  0.507473\n",
            "25454  22654  0.492945\n",
            "34394  36213  0.484154\n",
            "26117  24176  0.461936\n",
            "14124  14472  0.460664\n",
            "25018   1500  0.459376\n",
            "3214   40638  0.446175\n",
            "30326  17469  0.433155\n",
            "19777  46787  0.429784\n",
            "Cuisine for given input ['italian']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcP3t9xSnWuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}