{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ram_CS5293SP_Project3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "axjwjd6sYcH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4ede7549-644f-43a8-c339-88b48c94e178"
      },
      "source": [
        "import gensim as gensim\n",
        "import networkx\n",
        "import numpy as np  \n",
        "import os\n",
        "import pandas as pd  \n",
        "import glob\n",
        "import json\n",
        "import gc\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk import flatten\n",
        "from pickle import load\n",
        "from pickle import dump"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-usLfLJxZFeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Document normalize function\n",
        "def normalize_document(txt):\n",
        "    txt = txt.lower()\n",
        "    txt = txt.strip()\n",
        "    tokens = nltk.word_tokenize(txt)\n",
        "    clean_tokens = [t for t in tokens if t not in stop_words]\n",
        "    wordnet_lem = [WordNetLemmatizer().lemmatize(w) for w in clean_tokens]\n",
        "    stems = [nltk.stem.SnowballStemmer('english').stem(w) for w in wordnet_lem]\n",
        "    return ' '.join(stems)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD5DKaB-gCJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returning dataframe with normalized data\n",
        "def normalizedf(df_ini):\n",
        "  df_ini = df_ini\n",
        "  x = []\n",
        "  for i in df_ini['ingredients']:\n",
        "      i = ' '.join(i)\n",
        "      #print(i)\n",
        "      x.append(normalize_document(i))\n",
        "  df = df_ini\n",
        "  df[\"normalized_ing\"] = x\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xKaFKNVgX7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting into vector form\n",
        "def tfidfvecinput(input,df):\n",
        "  input = input\n",
        "  joined_input = []\n",
        "  input = ','.join(input)\n",
        "  joined_input.append(input)\n",
        "  input_normalized = []\n",
        "  input_normalized.append(normalize_document(joined_input[0]))\n",
        "  y = []\n",
        "  for every in df[\"normalized_ing\"]:\n",
        "      y.append(every)\n",
        "  y.insert(0,input_normalized[0])\n",
        "  vectorizer = TfidfVectorizer(stop_words='english')\n",
        "  tfidf_matrix_train = vectorizer.fit_transform(y).todense()\n",
        "  return tfidf_matrix_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0TCE1MVifdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding cosine similarity score with respect to input\n",
        "# Reference :- http://carrefax.com/new-blog/2017/7/4/cosine-similarity\n",
        "def cosinesim(mat,df):\n",
        "  simi = cosine_similarity(mat[0:1], mat).flatten()\n",
        "  #print(len(simi[1:]))\n",
        "  #print(len(df))\n",
        "  df[\"score\"] = simi[1:]\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uIO6CIplz4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting Top N ID's that are related to our input\n",
        "def getcloseid(df,N):\n",
        "  final_df = df.sort_values(by=[\"score\"],ascending=False)\n",
        "  result = final_df[[\"id\",\"score\"]].head(N)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frkJ_JlM2RBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving model\n",
        "def savemodel(df):\n",
        "  vectorizer = TfidfVectorizer(stop_words='english')\n",
        "  tfidf_matrix = vectorizer.fit_transform(df[\"normalized_ing\"]).todense()\n",
        "  cuisins = df[\"cuisine\"]\n",
        "  lb = LabelEncoder()\n",
        "  Y = lb.fit_transform(df[\"cuisine\"])\n",
        "  X = tfidf_matrix\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
        "  clf = RandomForestClassifier()\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test,y_pred)*100  \n",
        "  dump(clf, open('Rfcmodel.pkl', 'wb'))\n",
        "  print(accuracy)\n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDu4FQs9EKzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting cuisine based upon the input ingredients\n",
        "def predictcuisine(input,model,df):\n",
        "  joined_input = []\n",
        "  input = ','.join(input)\n",
        "  joined_input.append(input)\n",
        "  joi = []\n",
        "  joi.append(normalize_document(joined_input[0]))\n",
        "  vectorizer = TfidfVectorizer(stop_words='english')\n",
        "  tfidf_matrix = vectorizer.fit_transform(df[\"normalized_ing\"]).todense()\n",
        "  ini = vectorizer.transform([joi[0]]).todense()\n",
        "  y_predin = model.predict(ini)\n",
        "  lb = LabelEncoder()\n",
        "  Y = lb.fit_transform(df[\"cuisine\"])\n",
        "  return lb.inverse_transform(y_predin)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1yq8Bb-Mqrn",
        "colab_type": "text"
      },
      "source": [
        "## ***Execution*** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwhs32t5hYB9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "6cf387bd-8549-4369-c5e7-4bef0751dab3"
      },
      "source": [
        "\n",
        "input= [\"coriander powder\",\"ground turmeric\",\"red pepper flakes\",\"japanese eggplants\",\"plums\",\"grated parmesan cheese\",\"fresh parsley\",\"tomatoes with juice\"]\n",
        "df_ini = pd.read_json('yummly.json')\n",
        "norm_df = normalizedf(df_ini)\n",
        "mat = tfidfvecinput(input,norm_df)\n",
        "updated_df = cosinesim(mat,norm_df)\n",
        "N = 40\n",
        "if not os.path.exists('Rfcmodel.pkl'):\n",
        "  accu = savemodel(updated_df)\n",
        "else:\n",
        "  print(\"model is already executed with\",accu)\n",
        "model = load(open('Rfcmodel.pkl', 'rb'))\n",
        "print(\"Top10 ID's for given input\")\n",
        "print(getcloseid(updated_df,N))\n",
        "print(\"Cuisine for given input\",predictcuisine(input,model,df_ini))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model is already executed with 75.14770584538026\n",
            "Top10 ID's for given input\n",
            "          id     score\n",
            "26586  39414  0.527524\n",
            "25495  15840  0.507473\n",
            "25454  22654  0.492945\n",
            "34394  36213  0.484154\n",
            "26117  24176  0.461936\n",
            "14124  14472  0.460664\n",
            "25018   1500  0.459376\n",
            "3214   40638  0.446175\n",
            "30326  17469  0.433155\n",
            "19777  46787  0.429784\n",
            "13985  37784  0.420847\n",
            "21633  14661  0.419719\n",
            "32624  22292  0.418027\n",
            "35776  26639  0.414957\n",
            "9290    1131  0.411977\n",
            "34723  35183  0.410843\n",
            "15372  20021  0.407432\n",
            "37774  18966  0.404435\n",
            "9351   35415  0.401782\n",
            "32712  35985  0.399665\n",
            "39704   1923  0.399622\n",
            "38668  43074  0.399397\n",
            "38808  12592  0.397190\n",
            "1444   20429  0.396928\n",
            "19909  18122  0.394279\n",
            "5907   48958  0.392626\n",
            "9479     740  0.391821\n",
            "23027   6974  0.391534\n",
            "39691  33890  0.391122\n",
            "2022   40370  0.389360\n",
            "9169   20096  0.388881\n",
            "36142  11114  0.386660\n",
            "16720  29324  0.381516\n",
            "14816  37172  0.378523\n",
            "32961  20125  0.377804\n",
            "13     41995  0.376809\n",
            "38885  21193  0.376413\n",
            "32890  19138  0.376034\n",
            "37048  14833  0.373698\n",
            "28567  30675  0.373659\n",
            "Cuisine for given input ['italian']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcP3t9xSnWuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}